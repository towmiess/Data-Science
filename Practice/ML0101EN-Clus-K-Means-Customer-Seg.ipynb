{"cells":[{"cell_type":"markdown","id":"20293928-6f4d-4b02-b645-9f8ceeb1742a","metadata":{},"outputs":[],"source":["\n","<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n","\n","\n","# K-Means Clustering\n","\n","\n","Estimated time needed: **25** minutes\n","    \n","\n","## Objectives\n","\n","After completing this lab you will be able to:\n","\n","* Use scikit-learn's K-Means Clustering to cluster data\n"]},{"cell_type":"markdown","id":"f5c49dc6-c555-440e-a4ff-bbd48d4b25c8","metadata":{},"outputs":[],"source":["## Introduction\n","\n","There are many models for **clustering** out there. In this notebook, we will be presenting the model that is considered one of the simplest models amongst them. Despite its simplicity, the **K-means** is vastly used for clustering in many data science applications, it is especially useful if you need to quickly discover insights from **unlabeled data**. In this notebook, you will learn how to use k-Means for customer segmentation.\n","\n","Some real-world applications of k-means:\n","- Customer segmentation\n","- Understand what the visitors of a website are trying to accomplish\n","- Pattern recognition\n","- Machine learning\n","- Data compression\n","\n","\n","In this notebook we practice k-means clustering with 2 examples:\n","- k-means on a random generated dataset\n","- Using k-means for customer segmentation\n"]},{"cell_type":"markdown","id":"8c223dd6-ec13-415b-8fb1-a3b2879c87c1","metadata":{},"outputs":[],"source":["<h1>Table of contents</h1>\n","\n","<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n","    <ul>\n","        <li><a href=\"#random_generated_dataset\">k-Means on a randomly generated dataset</a></li>\n","            <ol>\n","                <li><a href=\"#setting_up_K_means\">Setting up K-Means</a></li>\n","                <li><a href=\"#creating_visual_plot\">Creating the Visual Plot</a></li>\n","            </ol>\n","        <p></p>\n","        <li><a href=\"#customer_segmentation_K_means\">Customer Segmentation with K-Means</a></li>\n","            <ol>\n","                <li><a href=\"#pre_processing\">Pre-processing</a></li>\n","                <li><a href=\"#modeling\">Modeling</a></li>\n","                <li><a href=\"#insights\">Insights</a></li>\n","            </ol>\n","    </ul>\n","</div>\n","<br>\n","<hr>\n"]},{"cell_type":"markdown","id":"55e5098c-6acd-471a-989e-fd6cc46dcc84","metadata":{},"outputs":[],"source":["### Import libraries\n","Let's first import the required libraries.\n","Also run <b> %matplotlib inline </b> since we will be plotting in this section.\n"]},{"cell_type":"code","id":"79125bf2-0645-49af-ae91-fa59da1c75a4","metadata":{},"outputs":[],"source":["# Surpress warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn"]},{"cell_type":"code","id":"7cc52586-f5c1-475a-8933-b8b2450c42ee","metadata":{},"outputs":[],"source":["import random \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.cluster import KMeans \nfrom sklearn.datasets import make_blobs \n%matplotlib inline"]},{"cell_type":"markdown","id":"15016d9d-cdb3-4313-8fef-f23f2f85af80","metadata":{},"outputs":[],"source":["<h1 id=\"random_generated_dataset\">k-Means on a randomly generated dataset</h1>\n","\n","Let's create our own dataset for this lab!\n"]},{"cell_type":"markdown","id":"8f710b74-a50a-4867-84cd-0e7ae3bf5921","metadata":{},"outputs":[],"source":["First we need to set a random seed. Use <b>numpy's random.seed()</b> function, where the seed will be set to <b>0</b>.\n"]},{"cell_type":"code","id":"78c4a778-e8e6-49dd-a096-e1787d04e23f","metadata":{},"outputs":[],"source":["np.random.seed(0)"]},{"cell_type":"markdown","id":"a458be33-b06f-43d1-8566-e933b8797825","metadata":{},"outputs":[],"source":["Next we will be making <i> random clusters </i> of points by using the <b> make_blobs </b> class. The <b> make_blobs </b> class can take in many inputs, but we will be using these specific ones. <br> <br>\n","<b> <u> Input </u> </b>\n","<ul>\n","    <li> <b>n_samples</b>: The total number of points equally divided among clusters. </li>\n","    <ul> <li> Value will be: 5000 </li> </ul>\n","    <li> <b>centers</b>: The number of centers to generate, or the fixed center locations. </li>\n","    <ul> <li> Value will be: [[4, 4], [-2, -1], [2, -3],[1,1]] </li> </ul>\n","    <li> <b>cluster_std</b>: The standard deviation of the clusters. </li>\n","    <ul> <li> Value will be: 0.9 </li> </ul>\n","</ul>\n","<br>\n","<b> <u> Output </u> </b>\n","<ul>\n","    <li> <b>X</b>: Array of shape [n_samples, n_features]. (Feature Matrix)</li>\n","    <ul> <li> The generated samples. </li> </ul> \n","    <li> <b>y</b>: Array of shape [n_samples]. (Response Vector)</li>\n","    <ul> <li> The integer labels for cluster membership of each sample. </li> </ul>\n","</ul>\n"]},{"cell_type":"code","id":"5fda8f32-3d97-4063-8e00-7e685a4d6056","metadata":{},"outputs":[],"source":["X, y = make_blobs(n_samples=5000, centers=[[4,4], [-2, -1], [2, -3], [1, 1]], cluster_std=0.9)"]},{"cell_type":"markdown","id":"eb2e1310-91d5-4e4f-887e-8c760375549d","metadata":{},"outputs":[],"source":["Display the scatter plot of the randomly generated data.\n"]},{"cell_type":"code","id":"0c358206-729e-4bd1-aa14-fe4a533114bc","metadata":{},"outputs":[],"source":["plt.scatter(X[:, 0], X[:, 1], marker='.')"]},{"cell_type":"markdown","id":"70518379-e9ad-4161-abc1-8ab92475c186","metadata":{},"outputs":[],"source":["<h2 id=\"setting_up_K_means\">Setting up K-Means</h2>\n","Now that we have our random data, let's set up our K-Means Clustering.\n"]},{"cell_type":"markdown","id":"f2591ca7-14f1-4640-ad70-dc80eab5f6df","metadata":{},"outputs":[],"source":["The KMeans class has many parameters that can be used, but we will be using these three:\n","<ul>\n","    <li> <b>init</b>: Initialization method of the centroids. </li>\n","    <ul>\n","        <li> Value will be: \"k-means++\" </li>\n","        <li> k-means++: Selects initial cluster centers for k-mean clustering in a smart way to speed up convergence.</li>\n","    </ul>\n","    <li> <b>n_clusters</b>: The number of clusters to form as well as the number of centroids to generate. </li>\n","    <ul> <li> Value will be: 4 (since we have 4 centers)</li> </ul>\n","    <li> <b>n_init</b>: Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia. </li>\n","    <ul> <li> Value will be: 12 </li> </ul>\n","</ul>\n","\n","Initialize KMeans with these parameters, where the output parameter is called <b>k_means</b>.\n"]},{"cell_type":"code","id":"e2c1e04f-351f-44d2-af6d-608d6f2b218e","metadata":{},"outputs":[],"source":["k_means = KMeans(init = \"k-means++\", n_clusters = 4, n_init = 12)"]},{"cell_type":"markdown","id":"8fcee2ec-6e70-4314-ac5f-65833f067573","metadata":{},"outputs":[],"source":["Now let's fit the KMeans model with the feature matrix we created above, <b> X </b>.\n"]},{"cell_type":"code","id":"29a91cf5-3d86-44d2-a4a7-80f5ae3145e3","metadata":{},"outputs":[],"source":["k_means.fit(X)"]},{"cell_type":"markdown","id":"d8ff5bb2-2f68-4090-b8ab-c202e16a70cd","metadata":{},"outputs":[],"source":["Now let's grab the labels for each point in the model using KMeans' <b> .labels\\_ </b> attribute and save it as <b> k_means_labels </b>.\n"]},{"cell_type":"code","id":"3051f1f7-6c76-4e72-925c-f807002a33a6","metadata":{},"outputs":[],"source":["k_means_labels = k_means.labels_\nk_means_labels"]},{"cell_type":"markdown","id":"69880d5c-79a6-4dc2-bc08-dd8b6e48d736","metadata":{},"outputs":[],"source":["We will also get the coordinates of the cluster centers using KMeans' <b> .cluster&#95;centers&#95; </b> and save it as <b> k_means_cluster_centers </b>.\n"]},{"cell_type":"code","id":"b19d5805-5d79-4326-9d42-132a0de7907d","metadata":{},"outputs":[],"source":["k_means_cluster_centers = k_means.cluster_centers_\nk_means_cluster_centers"]},{"cell_type":"markdown","id":"52f49e4d-3cf6-446b-a570-c10d688d84b3","metadata":{},"outputs":[],"source":["<h2 id=\"creating_visual_plot\">Creating the Visual Plot</h2>\n","\n","So now that we have the random data generated and the KMeans model initialized, let's plot them and see what it looks like!\n"]},{"cell_type":"markdown","id":"f9d3958a-7ade-41d7-8a89-bffb7c237007","metadata":{},"outputs":[],"source":["Please read through the code and comments to understand how to plot the model.\n"]},{"cell_type":"code","id":"533fa3a3-ae4b-48ce-bd59-22f7f1ddb789","metadata":{},"outputs":[],"source":["# Initialize the plot with the specified dimensions.\nfig = plt.figure(figsize=(6, 4))\n\n# Colors uses a color map, which will produce an array of colors based on\n# the number of labels there are. We use set(k_means_labels) to get the\n# unique labels.\ncolors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means_labels))))\n\n# Create a plot\nax = fig.add_subplot(1, 1, 1)\n\n# For loop that plots the data points and centroids.\n# k will range from 0-3, which will match the possible clusters that each\n# data point is in.\nfor k, col in zip(range(len([[4,4], [-2, -1], [2, -3], [1, 1]])), colors):\n\n    # Create a list of all data points, where the data points that are \n    # in the cluster (ex. cluster 0) are labeled as true, else they are\n    # labeled as false.\n    my_members = (k_means_labels == k)\n    \n    # Define the centroid, or cluster center.\n    cluster_center = k_means_cluster_centers[k]\n    \n    # Plots the datapoints with color col.\n    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n    \n    # Plots the centroids with specified color, but with a darker outline\n    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=6)\n\n# Title of the plot\nax.set_title('KMeans')\n\n# Remove x-axis ticks\nax.set_xticks(())\n\n# Remove y-axis ticks\nax.set_yticks(())\n\n# Show the plot\nplt.show()\n"]},{"cell_type":"markdown","id":"548f9674-3751-4954-8e88-0d5306055548","metadata":{},"outputs":[],"source":["## Practice\n","Try to cluster the above dataset into 3 clusters.  \n","Notice: do not generate the data again, use the same dataset as above.\n"]},{"cell_type":"code","id":"9044ebaf-e456-4da3-abd7-1afb881a99b8","metadata":{},"outputs":[],"source":["# write your code here\n\n"]},{"cell_type":"markdown","id":"201b978f-3c40-4576-bfa7-a359fb895b6a","metadata":{},"outputs":[],"source":["<details><summary>Click here for the solution</summary>\n","\n","```python\n","k_means3 = KMeans(init = \"k-means++\", n_clusters = 3, n_init = 12)\n","k_means3.fit(X)\n","fig = plt.figure(figsize=(6, 4))\n","colors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means3.labels_))))\n","ax = fig.add_subplot(1, 1, 1)\n","for k, col in zip(range(len(k_means3.cluster_centers_)), colors):\n","    my_members = (k_means3.labels_ == k)\n","    cluster_center = k_means3.cluster_centers_[k]\n","    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n","    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=6)\n","plt.show()\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","id":"8b51cc92-f1a3-4e10-984e-6f5aa3d1619f","metadata":{},"outputs":[],"source":["<h1 id=\"customer_segmentation_K_means\">Customer Segmentation with K-Means</h1>\n","\n","Imagine that you have a customer dataset, and you need to apply customer segmentation on this historical data.\n","Customer segmentation is the practice of partitioning a customer base into groups of individuals that have similar characteristics. It is a significant strategy as a business can target these specific groups of customers and effectively allocate marketing resources. For example, one group might contain customers who are high-profit and low-risk, that is, more likely to purchase products, or subscribe for a service. A business task is to retain those customers. Another group might include customers from non-profit organizations and so on.\n"]},{"cell_type":"markdown","id":"c496af1a-3f51-4545-9b41-7ad16cf5ca48","metadata":{},"outputs":[],"source":["### Load Data From CSV File  \n","Before you can work with the data, let's use pandas to read the dataset from IBM Object Storage.\n"]},{"cell_type":"code","id":"31383c09-3fbb-40d4-95a6-14563bd6bdc2","metadata":{},"outputs":[],"source":["import pandas as pd\ncust_df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%204/data/Cust_Segmentation.csv\")\ncust_df.head()"]},{"cell_type":"markdown","id":"4b2e59b7-2626-472c-9953-1f7df4606155","metadata":{},"outputs":[],"source":["<h2 id=\"pre_processing\">Pre-processing</h2\n"]},{"cell_type":"markdown","id":"91ee63a6-ebc5-4a54-8592-766a96e83396","metadata":{},"outputs":[],"source":["As you can see, __Address__ in this dataset is a categorical variable. The k-means algorithm isn't directly applicable to categorical variables because the Euclidean distance function isn't really meaningful for discrete variables. So, let's drop this feature and run clustering.\n"]},{"cell_type":"code","id":"b8abda07-296f-4dd6-b40d-b23c0f57adf1","metadata":{},"outputs":[],"source":["df = cust_df.drop('Address', axis=1)\ndf.head()"]},{"cell_type":"markdown","id":"32d7c1c1-6b8e-4d69-9e6e-2c1679453a97","metadata":{},"outputs":[],"source":["#### Normalizing over the standard deviation\n","Now let's normalize the dataset. But why do we need normalization in the first place? Normalization is a statistical method that helps mathematical-based algorithms to interpret features with different magnitudes and distributions equally. We use __StandardScaler()__ to normalize our dataset.\n"]},{"cell_type":"code","id":"ab6d8f6b-28b9-482c-b516-fd74f49fb882","metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\nX = df.values[:,1:]\nX = np.nan_to_num(X)\nClus_dataSet = StandardScaler().fit_transform(X)\nClus_dataSet"]},{"cell_type":"markdown","id":"5da3389e-481b-4c8c-ab09-dea6ce395e93","metadata":{},"outputs":[],"source":["<h2 id=\"modeling\">Modeling</h2>\n"]},{"cell_type":"markdown","id":"b4127d2f-aaee-45c7-b05f-d4f7fff21aa8","metadata":{},"outputs":[],"source":["In our example (if we didn't have access to the k-means algorithm), it would be the same as guessing that each customer group would have certain age, income, education, etc, with multiple tests and experiments. However, using the K-means clustering we can do all this process much easier.\n","\n","Let's apply k-means on our dataset, and take a look at cluster labels.\n"]},{"cell_type":"code","id":"52755792-a253-4c34-9993-8ec54b21a09b","metadata":{},"outputs":[],"source":["clusterNum = 3\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(X)\nlabels = k_means.labels_\nprint(labels)"]},{"cell_type":"markdown","id":"c6880044-80f6-4502-8851-df5c42cb19d7","metadata":{},"outputs":[],"source":["<h2 id=\"insights\">Insights</h2>\n","\n","We assign the labels to each row in the dataframe.\n"]},{"cell_type":"code","id":"e40d855f-690a-41b5-a244-85a366528ffc","metadata":{},"outputs":[],"source":["df[\"Clus_km\"] = labels\ndf.head(5)"]},{"cell_type":"markdown","id":"e767eaab-0612-44fd-872c-3fc537c7ac17","metadata":{},"outputs":[],"source":["We can easily check the centroid values by averaging the features in each cluster.\n"]},{"cell_type":"code","id":"e6fd8f28-21fb-473c-b2c4-04e6650e97fb","metadata":{},"outputs":[],"source":["df.groupby('Clus_km').mean()"]},{"cell_type":"markdown","id":"8aa0b3dd-7586-4695-825c-afda0cdbdcae","metadata":{},"outputs":[],"source":["Now, let's look at the distribution of customers based on their age and income:\n"]},{"cell_type":"code","id":"04890b4f-09d3-4104-971d-d2de6fb2a949","metadata":{},"outputs":[],"source":["area = np.pi * ( X[:, 1])**2  \nplt.scatter(X[:, 0], X[:, 3], s=area, c=labels.astype(np.float), alpha=0.5)\nplt.xlabel('Age', fontsize=18)\nplt.ylabel('Income', fontsize=16)\n\nplt.show()\n"]},{"cell_type":"code","id":"63af6fc3-e2df-413c-b3dc-7cd8315bd7d0","metadata":{},"outputs":[],"source":["from mpl_toolkits.mplot3d import Axes3D \nfig = plt.figure(1, figsize=(8, 6))\nplt.clf()\nax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n\nplt.cla()\n# plt.ylabel('Age', fontsize=18)\n# plt.xlabel('Income', fontsize=16)\n# plt.zlabel('Education', fontsize=16)\nax.set_xlabel('Education')\nax.set_ylabel('Age')\nax.set_zlabel('Income')\n\nax.scatter(X[:, 1], X[:, 0], X[:, 3], c= labels.astype(np.float))\n"]},{"cell_type":"markdown","id":"8a9a60bf-bf04-4486-9de7-87f884347170","metadata":{},"outputs":[],"source":["k-means will partition your customers into mutually exclusive groups, for example, into 3 clusters. The customers in each cluster are similar to each other demographically.\n","Now we can create a profile for each group, considering the common characteristics of each cluster. \n","For example, the 3 clusters can be:\n","\n","- AFFLUENT, EDUCATED AND OLD AGED\n","- MIDDLE AGED AND MIDDLE INCOME\n","- YOUNG AND LOW INCOME\n"]},{"cell_type":"markdown","id":"247139e2-da55-4611-8e86-22ee92ab9765","metadata":{},"outputs":[],"source":["### Thank you for completing this lab!\n","\n","\n","## Author\n","\n","Saeed Aghabozorgi\n","\n","\n","### Other Contributors\n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\" target=\"_blank\">Joseph Santarcangelo</a>\n","\n","## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n","\n","<!--\n","## Change Log\n","\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-11-03  | 2.1  | Lakshmi  |  Updated URL of csv |\n","| 2020-08-27  | 2.0  | Lavanya  |  Moved lab to course repo in GitLab |\n","|   |   |   |   |\n","|   |   |   |   |\n","--!>\n","\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"f6883c363dbe1447e9f13039a348569d7d36434aeead360646c9d41f734a261a"},"nbformat":4,"nbformat_minor":4}